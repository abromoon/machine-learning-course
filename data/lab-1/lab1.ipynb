{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e2123b",
   "metadata": {},
   "source": [
    "# Обзор алгоритмов машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b23270",
   "metadata": {},
   "source": [
    "## 1. Особенности работы алгоритмов\n",
    "\n",
    "Представьте графически работу различных алгортмов машинного обучения и сохраните картинки в отчете (удобней всего в google-docs). Для этого:\n",
    "* Возьмите датасет вашего варианта (см. список ниже). Найдите два **количественных** признака, от которых сильнее всего зависит целевой. Далее работайте с датасетом, содержащим только эти два признака и целевой.\n",
    "* Постройте график рассеяния всей выборки (отобразив цветом целевой класс) и небольшой случайной подвыборки, на которой вы будете тестировать алгоритмы (несколько десятков/сотен объектов). \n",
    "* Постройте карты работы следующих алгоритмов для разных значений параметров: sklearn.tree.DecisionTreeClassifier, sklearn.neighbors.KNeighborsClassifier, sklearn.svm.SVC с rbf ядром. Подберите параметры так, чтобы алгоритм оказался недообучен и переобучен. Отобразите те области карты, на которых лучше всего видна степень обученности модели и разместите две картинки в один ряд в отчете\n",
    "* Сравните карты работы линейной регрессии sklearn.linear_model.LinearRegression с картой одного из более устойчивых линейных алгоритмов: sklearn.linear_model.LogisticRegression или sklearn.linear_model.RidgeCV или sklearn.svm.LinearSVC (разместите их в один ряд в отчете)\n",
    "* Постройте карту работы наивного Байесовского классификатора sklearn.naive_bayes.GaussianNB\n",
    "* Постройте карту работы композиции деревьев. Для небольших выборок лучше всего использовать sklearn.ensemble.ExtraTreesClassifier\n",
    "\n",
    "## 2. Метрики качества\n",
    "\n",
    "* Для логистической регрессии и переобученного дерева предскажите вероятности класса 1 для всех объектов *полной* выборки. Постройте на одном графике разными полупрозрачными цветами нормированные гистограммы вероятностей для обоих целевых классов (разместите гистограммы обоих алгоритмов друг рядом с другом в отчете).\n",
    "* Найдите визуально наилучшее пороговое значение вероятности, которое отделяет один класс от другого для каждого алгоритма. Вычислите для этого порогового значения [метрики качества](https://en.wikipedia.org/wiki/Confusion_matrix): матрицу ошибок, Accuracy, TPR, FPR, TNR, FNR, Precision, Recall, F1-меру, Selectivity, Specificity, Balanced accuracy, Adjusted balanced accuracy (sklearn.metrics.balanced_accuracy_score). Оформите результаты в отчете в виде таблицы\n",
    "* Прикрепите в Moodle ваш ноутбук и ссылку на ваш отчет (его нужно расшарить всем для чтения кнопкой Share)\n",
    "\n",
    "## Варианты датасетов:\n",
    "1. [Hepatitis C Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/hepatitis-c-dataset) (целевой признак: пол пациента)\n",
    "2. [Russian Demography Data](https://www.kaggle.com/datasets/dwdkills/russian-demography) (целевой признак: year<=2004)\n",
    "3. [House prices](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data?select=train.csv) (целевой признак: LotArea<=9480)\n",
    "4. [Cryptocurrency Closing Price Prediction](https://zindi.africa/competitions/cryptocurrency-closing-price-prediction/data) (целевой признак: volatility<=0.013, удалите все строки, где не задана volatility)\n",
    "5. [Video Game Sales](https://www.kaggle.com/datasets/rush4ratio/video-game-sales-with-ratings) (целевой признак: Rating==E)\n",
    "6. [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) (целевой признак: Amount<=22)\n",
    "7. [Pokemon Dataset with Team Combat](https://www.kaggle.com/code/tuannguyenvananh/descriptive-analysis-pokemon-eda-feat-satoshi/data?select=pokemon.csv) (целевой признак: Legendary)\n",
    "8. [TMDB 5000 Movie Dataset](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata?select=tmdb_5000_movies.csv) (целевой признак: revenue>19млн)\n",
    "9. [Body Fat Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/body-fat-prediction-dataset) (целевой признак: Neck<=38)\n",
    "10. [Chess Game Dataset](https://www.kaggle.com/datasets/datasnaek/chess?select=games.csv) (целевой признак: winner==white)\n",
    "11. [Red Wine Quality](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009) (целевой признак: residual sugar <= 2.2)\n",
    "12. [Heart Failure Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction) (целевой признак: пол)\n",
    "13. [Car Price Prediction Multiple Linear Regression](https://www.kaggle.com/datasets/hellbuoy/car-price-prediction) (целевой признак: horsepower <= 100)\n",
    "14. [Body performance Data](https://www.kaggle.com/datasets/kukuroo3/body-performance-data) (целевой признак: возраст <= 40)\n",
    "15. [World Happiness Report](https://www.kaggle.com/datasets/unsdsn/world-happiness) (целевой признак: Family <= 1)\n",
    "16. [Students Performance in Exams](https://www.kaggle.com/datasets/spscientist/students-performance-in-exams) (целевой признак: lunch)\n",
    "17. [Pima Indians Diabetes Database](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database) (целевой признак: возраст <= 30)\n",
    "18. [IBM HR Analytics Employee Attrition & Performance](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset) (целевой признак: MaritalStatus==Married - бинарная классификация)\n",
    "19. [Acoustic Extinguisher Fire Dataset](https://www.kaggle.com/datasets/muratkokludataset/acoustic-extinguisher-fire-dataset) (целевой признак: FUEL==gasoline - бинарная классификация)\n",
    "20. [Pumpkin Classification : Autoviz](https://www.kaggle.com/datasets/muratkokludataset/pumpkin-seeds-dataset) (целевой признак: Compactness<=0.7)\n",
    "21. [Dry Bean Dataset](https://www.kaggle.com/datasets/muratkokludataset/dry-bean-dataset) (целевой признак: Class==DERMASON)\n",
    "22. [California Housing Prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices) (целевой признак: ocean_proximity == '<1H OCEAN')\n",
    "23. [Data Science for Good: PASSNYC](https://www.kaggle.com/datasets/passnyc/data-science-for-good?resource=download) (целевой признак: Percent Black <= 40)\n",
    "24. [Spotify Song Attributes](https://www.kaggle.com/datasets/geomack/spotifyclassification) (целевой признак: acousticness<=0.1)\n",
    "25. [Real Estate DataSet](https://www.kaggle.com/datasets/arslanali4343/real-estate-dataset) (целевой признак: PTRATIO>=18.84)\n",
    "26. [Glass Classification](https://www.kaggle.com/datasets/uciml/glass) (целевой признак: Type==2)\n",
    "27. [Car information dataset](https://www.kaggle.com/datasets/tawfikelmetwally/automobile-dataset) (целевой признак: model_year>=77)\n",
    "28. [Sleep Health and Lifestyle Dataset](https://www.kaggle.com/datasets/uom190346a/sleep-health-and-lifestyle-dataset) (целевой признак: Sleep Disorder == None)\n",
    "29. [Другой датасет](https://www.kaggle.com/datasets) по согласованию с преподавателем практики и с изменением целевого признака (**датасеты у всех должны быть разными**). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeabb24",
   "metadata": {},
   "source": [
    "## Полезные кусочки кода\n",
    "\n",
    "### отображение статистики:\n",
    "```\n",
    "pd.options.display.max_columns = data.shape[1]\n",
    "data.describe(include='all')\n",
    "```\n",
    "\n",
    "### поиск \"сильных\" признаков:\n",
    "```\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.dpi':300})\n",
    "label = 'укажите ваш целевой признак'\n",
    "features = [c for c in data.columns if c != label and data.dtypes[c] != 'object']\n",
    "X = data.loc[:,features]\n",
    "y = data[label]\n",
    "mi = sklearn.feature_selection.mutual_info_classif(X, y)\n",
    "ax = sns.barplot(x=mi, y=features)\n",
    "```\n",
    "\n",
    "### график рассеяния:\n",
    "```\n",
    "ax = sns.scatterplot(data=data, x='имя столбца1', y='имя столбца2', hue=label, palette=\"deep\")\n",
    "```\n",
    "\n",
    "### карта предсказания классификатора (цвет - вероятность класса 1):\n",
    "```\n",
    "x='имя столбца1'; y='имя столбца2'\n",
    "model = конструктор модели\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "xlim = (data[x].min(), data[x].max())\n",
    "ylim = (data[y].min(), data[y].max())\n",
    "model.fit(data.loc[:,[x,y]], data[label])\n",
    "grid_x = np.linspace(data[x].min(), data[x].max(), 100)\n",
    "grid_y = np.linspace(data[y].min(), data[y].max(), 100)\n",
    "xx, yy = np.meshgrid(grid_x, grid_y)\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "prediction = model.predict_proba(grid)[:,1].reshape(xx.shape)\n",
    "ax.contourf(xx, yy, prediction, cmap=sns.color_palette(\"rocket\", as_cmap=True))\n",
    "\n",
    "ax = sns.scatterplot(data=data, x=x, y=y, hue=label, palette=\"rocket\", ax=ax)\n",
    "ax.set_xlim(*xlim)\n",
    "ax.set_ylim(*ylim)\n",
    "```\n",
    "\n",
    "### гистограмма:\n",
    "```\n",
    "ax = sns.histplot(data=data, x=\"probability\", hue=label, kde=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53fcb26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
